(llm-eval-demo) zqin16@cdhai-Lambda-Vector:~/LLM_selection_demo$ /home/zqin16/miniforge3/envs/llm-eval-demo/bin/python /home/zqin16/LLM_selection_demo/scripts/collect_and_judge.py
Collecting biz_001:   0%|                                                           | 0/9 [00:00<?, ?model/s]{'prompt_tokens': 157, 'completion_tokens': 122, 'total_tokens': 279, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}
Collecting biz_001:  11%|█████▋                                             | 1/9 [00:01<00:12,  1.51s/model{'prompt_tokens': 157, 'completion_tokens': 122, 'total_tokens': 279, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}
Collecting biz_001:  22%|███████████▎                                       | 2/9 [00:04<00:15,  2.27s/model]{'prompt_tokens': 157, 'completion_tokens': 115, 'total_tokens': 272, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}
Collecting biz_001:  33%|█████████████████                                  | 3/9 [00:07<00:15,  2.52s/model]{'prompt_tokens': 157, 'completion_tokens': 121, 'total_tokens': 278, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}
Collecting biz_001:  44%|██████████████████████▋                            | 4/9 [00:09<00:12,  2.45s/model]{'prompt_tokens': 157, 'completion_tokens': 138, 'total_tokens': 295, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}
Collecting biz_001:  56%|████████████████████████████▎                      | 5/9 [00:11<00:09,  2.34s/model]{'input_tokens': 176, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}, 'output_tokens': 139, 'service_tier': 'standard'}
Collecting biz_001:  67%|██████████████████████████████████                 | 6/9 [00:12<00:05,  1.94s/model]{'input_tokens': 176, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}, 'output_tokens': 155, 'service_tier': 'standard'}
Collecting biz_001:  78%|███████████████████████████████████████▋           | 7/9 [00:15<00:04,  2.35s/model]{'input_tokens': 176, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}, 'output_tokens': 165, 'service_tier': 'standard'}
Collecting biz_001:  89%|█████████████████████████████████████████████▎     | 8/9 [00:20<00:03,  3.16s/model]{'input_tokens': 176, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}, 'output_tokens': 174, 'service_tier': 'standard'}
Collecting it_001:   0%|                                                            | 0/9 [00:00<?, ?model/s]{'prompt_tokens': 202, 'completion_tokens': 146, 'total_tokens': 348, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}
Collecting it_001:  11%|█████▊                                              | 1/9 [00:01<00:11,  1.45s/model]{'prompt_tokens': 202, 'completion_tokens': 170, 'total_tokens': 372, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}
Collecting it_001:  22%|███████████▌                                        | 2/9 [00:05<00:19,  2.83s/model]{'prompt_tokens': 202, 'completion_tokens': 130, 'total_tokens': 332, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}
Collecting it_001:  33%|█████████████████▎                                  | 3/9 [00:07<00:14,  2.38s/model]{'prompt_tokens': 202, 'completion_tokens': 118, 'total_tokens': 320, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}
Collecting it_001:  44%|███████████████████████                             | 4/9 [00:09<00:12,  2.54s/model]{'prompt_tokens': 202, 'completion_tokens': 138, 'total_tokens': 340, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}
Collecting it_001:  56%|████████████████████████████▉                       | 5/9 [00:11<00:09,  2.36s/model]{'input_tokens': 229, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}, 'output_tokens': 143, 'service_tier': 'standard'}
Collecting it_001:  67%|██████████████████████████████████▋                 | 6/9 [00:13<00:05,  1.98s/model]{'input_tokens': 229, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}, 'output_tokens': 155, 'service_tier': 'standard'}
Collecting it_001:  78%|████████████████████████████████████████▍           | 7/9 [00:15<00:04,  2.26s/model]{'input_tokens': 229, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}, 'output_tokens': 202, 'service_tier': 'standard'}
Collecting it_001:  89%|██████████████████████████████████████████████▏     | 8/9 [00:20<00:03,  3.13s/model]{'input_tokens': 229, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}, 'output_tokens': 228, 'service_tier': 'standard'}
Judging: 18resp [00:23,  1.30s/resp]                                                                         
(llm-eval-demo) zqin16@cdhai-Lambda-Vector:~/LLM_selection_demo$ 